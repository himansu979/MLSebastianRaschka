{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import sys\n",
    "# import utility\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn import datasets\n",
    "# from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from library import *\n",
    "import utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing python modules : http://effbot.org/zone/import-confusion.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\hisahoo.ISC\\\\Desktop\\\\Datascience\\\\Weekly-DS-meeting\\\\MLSebastianRaschka'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read file from local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['housing.data.txt', 'iris.csv', 'iris.data.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"dataset\"\n",
    "os.listdir(os.getcwd()+os.sep+data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir+os.sep+\"iris.data.txt\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3               4\n",
       "145  6.7  3.0  5.2  2.3  Iris-virginica\n",
       "146  6.3  2.5  5.0  1.9  Iris-virginica\n",
       "147  6.5  3.0  5.2  2.0  Iris-virginica\n",
       "148  6.2  3.4  5.4  2.3  Iris-virginica\n",
       "149  5.9  3.0  5.1  1.8  Iris-virginica"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([0, 1, 2, 3, 4], dtype='int64')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "type(df.loc[:, 4]) # pandas.core.series.Series\n",
    "print(np.unique(df.iloc[:, 4])) # loc and iloc will give same result here. because column names are integer\n",
    "#####np.bincount(df.iloc[:, 4]) # bin count is only for integer labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, 4].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Iris-versicolor    50\n",
       "Iris-setosa        50\n",
       "Iris-virginica     50\n",
       "Name: 4, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, 4].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "#label_encoder.fit(df.loc[:, 4])\n",
    "#df[\"target\"] = label_encoder.transform(df.loc[:, 4])\n",
    "# you can also replace above two line to one line\n",
    "df[\"target\"] = label_encoder.fit_transform(df.loc[:, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2    3            4  target\n",
      "0  5.1  3.5  1.4  0.2  Iris-setosa       0\n",
      "1  4.9  3.0  1.4  0.2  Iris-setosa       0\n",
      "2  4.7  3.2  1.3  0.2  Iris-setosa       0\n",
      "3  4.6  3.1  1.5  0.2  Iris-setosa       0\n",
      "4  5.0  3.6  1.4  0.2  Iris-setosa       0\n",
      "       0    1    2    3               4  target\n",
      "145  6.7  3.0  5.2  2.3  Iris-virginica       2\n",
      "146  6.3  2.5  5.0  1.9  Iris-virginica       2\n",
      "147  6.5  3.0  5.2  2.0  Iris-virginica       2\n",
      "148  6.2  3.4  5.4  2.3  Iris-virginica       2\n",
      "149  5.9  3.0  5.1  1.8  Iris-virginica       2\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_get_param_names', 'classes_', 'fit', 'fit_transform', 'get_params', 'inverse_transform', 'set_params', 'transform']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dir(label_encoder))\n",
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "label encoder arranges labels in alphabatically order. Here it happened to be in same order.\n",
    "it knows it has to do in 0, 1, 2 in this order. Lets change the order.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Iris-versicolor', 'Iris-virginica', 'Iris-setosa'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(label_encoder.transform(['Iris-virginica', 'Iris-setosa', 'Iris-versicolor'])) # 2, 0, 1\n",
    "label_encoder.inverse_transform([1, 2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50, 50, 50], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    50\n",
       "1    50\n",
       "0    50\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.unique(df.iloc[:, 4]))\n",
    "label_encoder.transform(np.unique(df.iloc[:, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Iris-setosa\n",
      "1 Iris-versicolor\n",
      "2 Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "for idx,label in enumerate(np.unique(df.iloc[:, 4])):\n",
    "    print(idx, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_mapping = {label:idx for idx,label in enumerate(np.unique(df.iloc[:, 4]))}\n",
    "class_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"target2\"] = df.iloc[:,4].map(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mapping = {\"Iris-setosa\":0, \"Iris-virginica\":1, \"Iris-versicolor\":2}\n",
    "#mapping\n",
    "#df.iloc[:, 4].map(mapping)\n",
    "#df.replace({\"4\": mapping})\n",
    "#mapping doesn't work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> There are three categories each of value_count 50, total counts 150 </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read file from sklearn datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#iris = datasets.load_iris()\n",
    "# X = iris.data[:, [2, 3]] # only take petal length, petal width\n",
    "# y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(type(iris.data), iris.data.shape)   # <class 'numpy.ndarray'> (150, 4)\n",
    "#print(type(iris.target), iris.target.shape) # <class 'numpy.ndarray'> (150,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.loc[:, [2,3]]\n",
    "y = df.target\n",
    "#X = df.iloc[0:100, [2,3]]\n",
    "#y = df.target[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> (150, 2)\n",
      "<class 'pandas.core.series.Series'> (150,)\n"
     ]
    }
   ],
   "source": [
    "print(type(X), X.shape)   \n",
    "print(type(y), y.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sc = StandardScaler()\n",
    "#sc.fit(X_train)\n",
    "#X_train_std = sc.transform(X_train)\n",
    "#X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_combined_std = np.vstack((X_train_std, X_test_std))\n",
    "#y_combined = np.hstack((y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X\n",
    "X_test = X\n",
    "y_train = y\n",
    "y_test = y\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "\n",
    "X_test_std = X_train_std\n",
    "X_combined_std = X_train_std\n",
    "y_combined = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### what is difference between vstack and hstack???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array((1,2,3))\n",
    "b = np.array((2,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,) (3,)\n"
     ]
    }
   ],
   "source": [
    "print(a.shape, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 2, 3, 4])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.hstack((a,b)).shape)\n",
    "np.hstack((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [2, 3, 4]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.vstack((a,b)).shape)\n",
    "np.vstack((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_std.shape\n",
    "X_test_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hisahoo.ISC\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\hisahoo.ISC\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=1, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1 = LogisticRegression(C=100.0, random_state=1)\n",
    "lr1.fit(X_train_std, y_train)\n",
    "lr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.20.0'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn; sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> due to above warnings defined a new model <br>\n",
    "solver : str, {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'}, default: 'liblinear'. -----> lbfgs <br>\n",
    "multi_class : str, {'ovr', 'multinomial', 'auto'}, default: 'ovr' -----> auto\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='auto',\n",
       "          n_jobs=None, penalty='l2', random_state=1, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(C=100.0, random_state=1, solver=\"lbfgs\", multi_class=\"auto\")\n",
    "lr.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> This plot is different from book, because different solver and multi_class </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#utility.plot_decision_regions_with_test(X_combined_std, y_combined, classifier=lr, test_idx=range(105, 150))\n",
    "\n",
    "utility.plot_decision_regions(X_combined_std, y_combined, classifier=lr)\n",
    "\n",
    "plt.xlabel('petal length [standardized]')\n",
    "plt.ylabel('petal width [standardized]')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('images/03_06.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#utility.plot_decision_regions_with_test(X_combined_std, y_combined, classifier=lr1, test_idx=range(105, 150))\n",
    "\n",
    "utility.plot_decision_regions(X_combined_std, y_combined, classifier=lr)\n",
    "\n",
    "plt.xlabel('petal length [standardized]')\n",
    "plt.ylabel('petal width [standardized]')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('images/03_06.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'warn'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.multi_class # ovr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.25048682e-01, 1.74951318e-01, 1.36488412e-13],\n",
       "       [8.25048682e-01, 1.74951318e-01, 1.36488412e-13],\n",
       "       [8.42057087e-01, 1.57942913e-01, 8.75586067e-14]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.predict_proba(X_test_std[:3, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.predict_proba(X_test_std[:3, :]).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.predict_proba(X_test_std[:3, :]).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.predict(X_test_std[:3, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict(X_test_std[0, :].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.3412724  -1.31297673] (2,)\n",
      "[[-1.3412724  -1.31297673]] (1, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_std[0, :], X_test_std[0, :].shape) # this is single sample, shape should be (1,2)\n",
    "print(X_test_std[0, :].reshape(1, -1), X_test_std[0, :].reshape(1,-1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on LogisticRegression in module sklearn.linear_model.logistic object:\n",
      "\n",
      "class LogisticRegression(sklearn.base.BaseEstimator, sklearn.linear_model.base.LinearClassifierMixin, sklearn.linear_model.base.SparseCoefMixin)\n",
      " |  Logistic Regression (aka logit, MaxEnt) classifier.\n",
      " |  \n",
      " |  In the multiclass case, the training algorithm uses the one-vs-rest (OvR)\n",
      " |  scheme if the 'multi_class' option is set to 'ovr', and uses the cross-\n",
      " |  entropy loss if the 'multi_class' option is set to 'multinomial'.\n",
      " |  (Currently the 'multinomial' option is supported only by the 'lbfgs',\n",
      " |  'sag' and 'newton-cg' solvers.)\n",
      " |  \n",
      " |  This class implements regularized logistic regression using the\n",
      " |  'liblinear' library, 'newton-cg', 'sag' and 'lbfgs' solvers. It can handle\n",
      " |  both dense and sparse input. Use C-ordered arrays or CSR matrices\n",
      " |  containing 64-bit floats for optimal performance; any other input format\n",
      " |  will be converted (and copied).\n",
      " |  \n",
      " |  The 'newton-cg', 'sag', and 'lbfgs' solvers support only L2 regularization\n",
      " |  with primal formulation. The 'liblinear' solver supports both L1 and L2\n",
      " |  regularization, with a dual formulation only for the L2 penalty.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <logistic_regression>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  penalty : str, 'l1' or 'l2', default: 'l2'\n",
      " |      Used to specify the norm used in the penalization. The 'newton-cg',\n",
      " |      'sag' and 'lbfgs' solvers support only l2 penalties.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |         l1 penalty with SAGA solver (allowing 'multinomial' + L1)\n",
      " |  \n",
      " |  dual : bool, default: False\n",
      " |      Dual or primal formulation. Dual formulation is only implemented for\n",
      " |      l2 penalty with liblinear solver. Prefer dual=False when\n",
      " |      n_samples > n_features.\n",
      " |  \n",
      " |  tol : float, default: 1e-4\n",
      " |      Tolerance for stopping criteria.\n",
      " |  \n",
      " |  C : float, default: 1.0\n",
      " |      Inverse of regularization strength; must be a positive float.\n",
      " |      Like in support vector machines, smaller values specify stronger\n",
      " |      regularization.\n",
      " |  \n",
      " |  fit_intercept : bool, default: True\n",
      " |      Specifies if a constant (a.k.a. bias or intercept) should be\n",
      " |      added to the decision function.\n",
      " |  \n",
      " |  intercept_scaling : float, default 1.\n",
      " |      Useful only when the solver 'liblinear' is used\n",
      " |      and self.fit_intercept is set to True. In this case, x becomes\n",
      " |      [x, self.intercept_scaling],\n",
      " |      i.e. a \"synthetic\" feature with constant value equal to\n",
      " |      intercept_scaling is appended to the instance vector.\n",
      " |      The intercept becomes ``intercept_scaling * synthetic_feature_weight``.\n",
      " |  \n",
      " |      Note! the synthetic feature weight is subject to l1/l2 regularization\n",
      " |      as all other features.\n",
      " |      To lessen the effect of regularization on synthetic feature weight\n",
      " |      (and therefore on the intercept) intercept_scaling has to be increased.\n",
      " |  \n",
      " |  class_weight : dict or 'balanced', default: None\n",
      " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
      " |      If not given, all classes are supposed to have weight one.\n",
      " |  \n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``.\n",
      " |  \n",
      " |      Note that these weights will be multiplied with sample_weight (passed\n",
      " |      through the fit method) if sample_weight is specified.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *class_weight='balanced'*\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional, default: None\n",
      " |      The seed of the pseudo random number generator to use when shuffling\n",
      " |      the data.  If int, random_state is the seed used by the random number\n",
      " |      generator; If RandomState instance, random_state is the random number\n",
      " |      generator; If None, the random number generator is the RandomState\n",
      " |      instance used by `np.random`. Used when ``solver`` == 'sag' or\n",
      " |      'liblinear'.\n",
      " |  \n",
      " |  solver : str, {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'},              default: 'liblinear'.\n",
      " |  \n",
      " |      Algorithm to use in the optimization problem.\n",
      " |  \n",
      " |      - For small datasets, 'liblinear' is a good choice, whereas 'sag' and\n",
      " |        'saga' are faster for large ones.\n",
      " |      - For multiclass problems, only 'newton-cg', 'sag', 'saga' and 'lbfgs'\n",
      " |        handle multinomial loss; 'liblinear' is limited to one-versus-rest\n",
      " |        schemes.\n",
      " |      - 'newton-cg', 'lbfgs' and 'sag' only handle L2 penalty, whereas\n",
      " |        'liblinear' and 'saga' handle L1 penalty.\n",
      " |  \n",
      " |      Note that 'sag' and 'saga' fast convergence is only guaranteed on\n",
      " |      features with approximately the same scale. You can\n",
      " |      preprocess the data with a scaler from sklearn.preprocessing.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         Stochastic Average Gradient descent solver.\n",
      " |      .. versionadded:: 0.19\n",
      " |         SAGA solver.\n",
      " |      .. versionchanged:: 0.20\n",
      " |          Default will change from 'liblinear' to 'lbfgs' in 0.22.\n",
      " |  \n",
      " |  max_iter : int, default: 100\n",
      " |      Useful only for the newton-cg, sag and lbfgs solvers.\n",
      " |      Maximum number of iterations taken for the solvers to converge.\n",
      " |  \n",
      " |  multi_class : str, {'ovr', 'multinomial', 'auto'}, default: 'ovr'\n",
      " |      If the option chosen is 'ovr', then a binary problem is fit for each\n",
      " |      label. For 'multinomial' the loss minimised is the multinomial loss fit\n",
      " |      across the entire probability distribution, *even when the data is\n",
      " |      binary*. 'multinomial' is unavailable when solver='liblinear'.\n",
      " |      'auto' selects 'ovr' if the data is binary, or if solver='liblinear',\n",
      " |      and otherwise selects 'multinomial'.\n",
      " |  \n",
      " |      .. versionadded:: 0.18\n",
      " |         Stochastic Average Gradient descent solver for 'multinomial' case.\n",
      " |      .. versionchanged:: 0.20\n",
      " |          Default will change from 'ovr' to 'auto' in 0.22.\n",
      " |  \n",
      " |  verbose : int, default: 0\n",
      " |      For the liblinear and lbfgs solvers set verbose to any positive\n",
      " |      number for verbosity.\n",
      " |  \n",
      " |  warm_start : bool, default: False\n",
      " |      When set to True, reuse the solution of the previous call to fit as\n",
      " |      initialization, otherwise, just erase the previous solution.\n",
      " |      Useless for liblinear solver. See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers.\n",
      " |  \n",
      " |  n_jobs : int or None, optional (default=None)\n",
      " |      Number of CPU cores used when parallelizing over classes if\n",
      " |      multi_class='ovr'\". This parameter is ignored when the ``solver`` is\n",
      " |      set to 'liblinear' regardless of whether 'multi_class' is specified or\n",
      " |      not. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
      " |      context. ``-1`` means using all processors.\n",
      " |      See :term:`Glossary <n_jobs>` for more details.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  \n",
      " |  coef_ : array, shape (1, n_features) or (n_classes, n_features)\n",
      " |      Coefficient of the features in the decision function.\n",
      " |  \n",
      " |      `coef_` is of shape (1, n_features) when the given problem is binary.\n",
      " |      In particular, when `multi_class='multinomial'`, `coef_` corresponds\n",
      " |      to outcome 1 (True) and `-coef_` corresponds to outcome 0 (False).\n",
      " |  \n",
      " |  intercept_ : array, shape (1,) or (n_classes,)\n",
      " |      Intercept (a.k.a. bias) added to the decision function.\n",
      " |  \n",
      " |      If `fit_intercept` is set to False, the intercept is set to zero.\n",
      " |      `intercept_` is of shape (1,) when the given problem is binary.\n",
      " |      In particular, when `multi_class='multinomial'`, `intercept_`\n",
      " |      corresponds to outcome 1 (True) and `-intercept_` corresponds to\n",
      " |      outcome 0 (False).\n",
      " |  \n",
      " |  n_iter_ : array, shape (n_classes,) or (1, )\n",
      " |      Actual number of iterations for all classes. If binary or multinomial,\n",
      " |      it returns only 1 element. For liblinear solver, only the maximum\n",
      " |      number of iteration across all classes is given.\n",
      " |  \n",
      " |      .. versionchanged:: 0.20\n",
      " |  \n",
      " |          In SciPy <= 1.0.0 the number of lbfgs iterations may exceed\n",
      " |          ``max_iter``. ``n_iter_`` will now report at most ``max_iter``.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.datasets import load_iris\n",
      " |  >>> from sklearn.linear_model import LogisticRegression\n",
      " |  >>> X, y = load_iris(return_X_y=True)\n",
      " |  >>> clf = LogisticRegression(random_state=0, solver='lbfgs',\n",
      " |  ...                          multi_class='multinomial').fit(X, y)\n",
      " |  >>> clf.predict(X[:2, :])\n",
      " |  array([0, 0])\n",
      " |  >>> clf.predict_proba(X[:2, :]) # doctest: +ELLIPSIS\n",
      " |  array([[9.8...e-01, 1.8...e-02, 1.4...e-08],\n",
      " |         [9.7...e-01, 2.8...e-02, ...e-08]])\n",
      " |  >>> clf.score(X, y)\n",
      " |  0.97...\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  SGDClassifier : incrementally trained logistic regression (when given\n",
      " |      the parameter ``loss=\"log\"``).\n",
      " |  LogisticRegressionCV : Logistic regression with built-in cross validation\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The underlying C implementation uses a random number generator to\n",
      " |  select features when fitting the model. It is thus not uncommon,\n",
      " |  to have slightly different results for the same input data. If\n",
      " |  that happens, try with a smaller tol parameter.\n",
      " |  \n",
      " |  Predict output may not match that of standalone liblinear in certain\n",
      " |  cases. See :ref:`differences from liblinear <liblinear_differences>`\n",
      " |  in the narrative documentation.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  LIBLINEAR -- A Library for Large Linear Classification\n",
      " |      http://www.csie.ntu.edu.tw/~cjlin/liblinear/\n",
      " |  \n",
      " |  SAG -- Mark Schmidt, Nicolas Le Roux, and Francis Bach\n",
      " |      Minimizing Finite Sums with the Stochastic Average Gradient\n",
      " |      https://hal.inria.fr/hal-00860051/document\n",
      " |  \n",
      " |  SAGA -- Defazio, A., Bach F. & Lacoste-Julien S. (2014).\n",
      " |      SAGA: A Fast Incremental Gradient Method With Support\n",
      " |      for Non-Strongly Convex Composite Objectives\n",
      " |      https://arxiv.org/abs/1407.0202\n",
      " |  \n",
      " |  Hsiang-Fu Yu, Fang-Lan Huang, Chih-Jen Lin (2011). Dual coordinate descent\n",
      " |      methods for logistic regression and maximum entropy models.\n",
      " |      Machine Learning 85(1-2):41-75.\n",
      " |      http://www.csie.ntu.edu.tw/~cjlin/papers/maxent_dual.pdf\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LogisticRegression\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.linear_model.base.LinearClassifierMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.linear_model.base.SparseCoefMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='warn', max_iter=100, multi_class='warn', verbose=0, warm_start=False, n_jobs=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          Training vector, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,) or (n_samples, n_targets)\n",
      " |          Target vector relative to X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,) optional\n",
      " |          Array of weights that are assigned to individual samples.\n",
      " |          If not provided, then each sample is given unit weight.\n",
      " |      \n",
      " |          .. versionadded:: 0.17\n",
      " |             *sample_weight* support to LogisticRegression.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Log of probability estimates.\n",
      " |      \n",
      " |      The returned estimates for all classes are ordered by the\n",
      " |      label of classes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like, shape = [n_samples, n_classes]\n",
      " |          Returns the log-probability of the sample for each class in the\n",
      " |          model, where classes are ordered as they are in ``self.classes_``.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Probability estimates.\n",
      " |      \n",
      " |      The returned estimates for all classes are ordered by the\n",
      " |      label of classes.\n",
      " |      \n",
      " |      For a multi_class problem, if multi_class is set to be \"multinomial\"\n",
      " |      the softmax function is used to find the predicted probability of\n",
      " |      each class.\n",
      " |      Else use a one-vs-rest approach, i.e calculate the probability\n",
      " |      of each class assuming it to be positive using the logistic function.\n",
      " |      and normalize these values across all the classes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like, shape = [n_samples, n_classes]\n",
      " |          Returns the probability of the sample for each class in the model,\n",
      " |          where classes are ordered as they are in ``self.classes_``.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model.base.LinearClassifierMixin:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Predict confidence scores for samples.\n",
      " |      \n",
      " |      The confidence score for a sample is the signed distance of that\n",
      " |      sample to the hyperplane.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)\n",
      " |          Confidence scores per (sample, class) combination. In the binary\n",
      " |          case, confidence score for self.classes_[1] where >0 means this\n",
      " |          class would be predicted.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class labels for samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape [n_samples]\n",
      " |          Predicted class label per sample.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model.base.SparseCoefMixin:\n",
      " |  \n",
      " |  densify(self)\n",
      " |      Convert coefficient matrix to dense array format.\n",
      " |      \n",
      " |      Converts the ``coef_`` member (back) to a numpy.ndarray. This is the\n",
      " |      default format of ``coef_`` and is required for fitting, so calling\n",
      " |      this method is only required on models that have previously been\n",
      " |      sparsified; otherwise, it is a no-op.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator\n",
      " |  \n",
      " |  sparsify(self)\n",
      " |      Convert coefficient matrix to sparse format.\n",
      " |      \n",
      " |      Converts the ``coef_`` member to a scipy.sparse matrix, which for\n",
      " |      L1-regularized models can be much more memory- and storage-efficient\n",
      " |      than the usual numpy.ndarray representation.\n",
      " |      \n",
      " |      The ``intercept_`` member is not converted.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For non-sparse models, i.e. when there are not many zeros in ``coef_``,\n",
      " |      this may actually *increase* memory usage, so use this method with\n",
      " |      care. A rule of thumb is that the number of zero elements, which can\n",
      " |      be computed with ``(coef_ == 0).sum()``, must be more than 50% for this\n",
      " |      to provide significant benefits.\n",
      " |      \n",
      " |      After calling this method, further fitting with the partial_fit\n",
      " |      method (if any) will not work until you call densify.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(lr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_estimator_type', '_get_param_names', '_predict_proba_lr', 'class_weight', 'classes_', 'coef_', 'decision_function', 'densify', 'dual', 'fit', 'fit_intercept', 'get_params', 'intercept_', 'intercept_scaling', 'max_iter', 'multi_class', 'n_iter_', 'n_jobs', 'penalty', 'predict', 'predict_log_proba', 'predict_proba', 'random_state', 'score', 'set_params', 'solver', 'sparsify', 'tol', 'verbose', 'warm_start']\n"
     ]
    }
   ],
   "source": [
    "print(dir(lr1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9], dtype=int32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.68175478, -4.93017223],\n",
       "       [ 2.69232528, -2.33600813],\n",
       "       [ 8.16323981,  6.99743803]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.42099752, -0.76918735, -9.29408734])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.3412724 , -1.31297673],\n",
       "       [-1.3412724 , -1.31297673],\n",
       "       [-1.39813811, -1.31297673]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_std[:3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.25048682e-01, 1.74951318e-01, 1.36488412e-13],\n",
       "       [8.25048682e-01, 1.74951318e-01, 1.36488412e-13],\n",
       "       [8.42057087e-01, 1.57942913e-01, 8.75586067e-14]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.predict_proba(X_test_std[:3, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.predict(X_test_std[:3, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_std[1, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.coef_.shape # 3 models, 2 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z = np.dot(lr1.coef_, X_test_std[2, :]) + lr1.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.99608176,  -1.46630562, -29.89489729])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.classes_[Z.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  7.99608176,  -1.46630562, -29.89489729])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob1 = Z\n",
    "prob1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comb_prob(X, coef, bias):\n",
    "    #prob = np.dot(lr1.coef_, X_test_std[2, :]) + lr1.intercept_\n",
    "    prob = np.dot(X, coef.T) + bias\n",
    "    #print(prob)\n",
    "    prob *= -1\n",
    "    np.exp(prob, prob)\n",
    "    prob += 1\n",
    "    np.reciprocal(prob, prob)\n",
    "    print(prob)\n",
    "    return prob/prob.sum(axis=1).reshape((prob.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_comb_prob(X_test_std[0, :], lr1.coef_, lr1.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_comb_prob(X_test_std[2, :], lr1.coef_, lr1.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.99534989e-01 2.11951085e-01 1.65353810e-13]\n",
      " [9.99534989e-01 2.11951085e-01 1.65353810e-13]\n",
      " [9.99663334e-01 1.87504792e-01 1.03946787e-13]\n",
      " [9.99357748e-01 2.38648448e-01 2.63037304e-13]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[8.25048682e-01, 1.74951318e-01, 1.36488412e-13],\n",
       "       [8.25048682e-01, 1.74951318e-01, 1.36488412e-13],\n",
       "       [8.42057087e-01, 1.57942913e-01, 8.75586067e-14],\n",
       "       [8.07231621e-01, 1.92768379e-01, 2.12468487e-13]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_comb_prob(X_test_std[:4,:], lr1.coef_, lr1.intercept_) # make this working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.25048682e-01, 1.74951318e-01, 1.36488412e-13],\n",
       "       [8.25048682e-01, 1.74951318e-01, 1.36488412e-13],\n",
       "       [8.42057087e-01, 1.57942913e-01, 8.75586067e-14],\n",
       "       [8.07231621e-01, 1.92768379e-01, 2.12468487e-13]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.predict_proba(X_test_std[:4, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.99663334e-01, 1.87504792e-01, 1.03946787e-13])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(Z) # this is individual probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prob(x, w, bias):\n",
    "    probs = np.array([])\n",
    "    for i in range(len(w)):\n",
    "        z = np.dot(x, w[i]) + bias[i]\n",
    "        prob = sigmoid(z)\n",
    "        probs = np.append(probs, prob)\n",
    "        #probs = np.append(probs, z)\n",
    "        \n",
    "    print(probs)\n",
    "    probs_normalized = np.array([i/np.sum(probs) for i in probs])\n",
    "    #probs_new = np.array([])\n",
    "    #for i in probs:\n",
    "        ##i = np.exp(i)/np.sum(np.exp(probs))\n",
    "    #    i = i/np.sum(probs)\n",
    "     #   probs_new = np.append(probs_new, i)\n",
    "        \n",
    "    return probs_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.99663334e-01 1.87504792e-01 1.03946787e-13]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([8.42057087e-01, 1.57942913e-01, 8.75586067e-14])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prob(X_test_std[2, :], lr1.coef_, lr1.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.99534989e-01 2.11951085e-01 1.65353810e-13]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([8.25048682e-01, 1.74951318e-01, 1.36488412e-13])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prob(X_test_std[0, :], lr1.coef_, lr1.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "https://www.kdnuggets.com/2016/07/softmax-regression-related-logistic-regression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
