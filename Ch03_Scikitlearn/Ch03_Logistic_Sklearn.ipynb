{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import sys\n",
    "# import utility\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn import datasets\n",
    "# from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from library import *\n",
    "import utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing python modules : http://effbot.org/zone/import-confusion.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\hisahoo.ISC\\\\Desktop\\\\Datascience\\\\Weekly-DS-meeting\\\\MLSebastianRaschka'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### read file from local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['housing.data.txt', 'iris.csv', 'iris.data.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"dataset\"\n",
    "os.listdir(os.getcwd()+os.sep+data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir+os.sep+\"iris.data.txt\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3               4\n",
       "145  6.7  3.0  5.2  2.3  Iris-virginica\n",
       "146  6.3  2.5  5.0  1.9  Iris-virginica\n",
       "147  6.5  3.0  5.2  2.0  Iris-virginica\n",
       "148  6.2  3.4  5.4  2.3  Iris-virginica\n",
       "149  5.9  3.0  5.1  1.8  Iris-virginica"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([0, 1, 2, 3, 4], dtype='int64')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "type(df.loc[:, 4]) # pandas.core.series.Series\n",
    "print(np.unique(df.iloc[:, 4])) # loc and iloc will give same result here. because column names are integer\n",
    "#####np.bincount(df.iloc[:, 4]) # bin count is only for integer labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:, 4].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Iris-setosa        50\n",
       "Iris-versicolor    50\n",
       "Iris-virginica     50\n",
       "Name: 4, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, 4].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "#label_encoder.fit(df.loc[:, 4])\n",
    "#df[\"target\"] = label_encoder.transform(df.loc[:, 4])\n",
    "# you can also replace above two line to one line\n",
    "df[\"target\"] = label_encoder.fit_transform(df.loc[:, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2    3            4  target\n",
      "0  5.1  3.5  1.4  0.2  Iris-setosa       0\n",
      "1  4.9  3.0  1.4  0.2  Iris-setosa       0\n",
      "2  4.7  3.2  1.3  0.2  Iris-setosa       0\n",
      "3  4.6  3.1  1.5  0.2  Iris-setosa       0\n",
      "4  5.0  3.6  1.4  0.2  Iris-setosa       0\n",
      "       0    1    2    3               4  target\n",
      "145  6.7  3.0  5.2  2.3  Iris-virginica       2\n",
      "146  6.3  2.5  5.0  1.9  Iris-virginica       2\n",
      "147  6.5  3.0  5.2  2.0  Iris-virginica       2\n",
      "148  6.2  3.4  5.4  2.3  Iris-virginica       2\n",
      "149  5.9  3.0  5.1  1.8  Iris-virginica       2\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_get_param_names', 'classes_', 'fit', 'fit_transform', 'get_params', 'inverse_transform', 'set_params', 'transform']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dir(label_encoder))\n",
    "label_encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "label encoder arranges labels in alphabatically order. Here it happened to be in same order.\n",
    "it knows it has to do in 0, 1, 2 in this order. Lets change the order.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Iris-versicolor', 'Iris-virginica', 'Iris-setosa'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(label_encoder.transform(['Iris-virginica', 'Iris-setosa', 'Iris-versicolor'])) # 2, 0, 1\n",
    "label_encoder.inverse_transform([1, 2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50, 50, 50], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    50\n",
       "1    50\n",
       "0    50\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.unique(df.iloc[:, 4]))\n",
    "label_encoder.transform(np.unique(df.iloc[:, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Iris-setosa\n",
      "1 Iris-versicolor\n",
      "2 Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "for idx,label in enumerate(np.unique(df.iloc[:, 4])):\n",
    "    print(idx, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_mapping1 = {label:idx for idx,label in enumerate(np.unique(df.iloc[:, 4]))}\n",
    "class_mapping1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_mapping = {'Iris-setosa':1, 'Iris-versicolor':0, 'Iris-virginica':0} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"target2\"] = df.iloc[:,4].map(class_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0    1    2    3            4  target  target2\n",
      "0  5.1  3.5  1.4  0.2  Iris-setosa       0        1\n",
      "1  4.9  3.0  1.4  0.2  Iris-setosa       0        1\n",
      "2  4.7  3.2  1.3  0.2  Iris-setosa       0        1\n",
      "3  4.6  3.1  1.5  0.2  Iris-setosa       0        1\n",
      "4  5.0  3.6  1.4  0.2  Iris-setosa       0        1\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "#print(df.iloc[60:80,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mapping = {\"Iris-setosa\":0, \"Iris-virginica\":1, \"Iris-versicolor\":2}\n",
    "#mapping\n",
    "#df.iloc[:, 4].map(mapping)\n",
    "#df.replace({\"4\": mapping})\n",
    "#mapping doesn't work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> There are three categories each of value_count 50, total counts 150 </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read file from sklearn datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#iris = datasets.load_iris()\n",
    "# X = iris.data[:, [2, 3]] # only take petal length, petal width\n",
    "# y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(type(iris.data), iris.data.shape)   # <class 'numpy.ndarray'> (150, 4)\n",
    "#print(type(iris.target), iris.target.shape) # <class 'numpy.ndarray'> (150,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.loc[:, [2,3]]\n",
    "y = df.target2\n",
    "#X = df.iloc[0:100, [2,3]]\n",
    "#y = df.target[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'> (150, 2)\n",
      "<class 'pandas.core.series.Series'> (150,)\n"
     ]
    }
   ],
   "source": [
    "print(type(X), X.shape)   \n",
    "print(type(y), y.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sc = StandardScaler()\n",
    "#sc.fit(X_train)\n",
    "#X_train_std = sc.transform(X_train)\n",
    "#X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_combined_std = np.vstack((X_train_std, X_test_std))\n",
    "#y_combined = np.hstack((y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X\n",
    "X_test = X\n",
    "y_train = y\n",
    "y_test = y\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "\n",
    "X_test_std = X_train_std\n",
    "X_combined_std = X_train_std\n",
    "y_combined = y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### what is difference between vstack and hstack???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.array((1,2,3))\n",
    "b = np.array((2,3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,) (3,)\n"
     ]
    }
   ],
   "source": [
    "print(a.shape, b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 2, 3, 4])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.hstack((a,b)).shape)\n",
    "np.hstack((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [2, 3, 4]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.vstack((a,b)).shape)\n",
    "np.vstack((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_std.shape\n",
    "X_test_std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hisahoo.ISC\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=1, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1 = LogisticRegression(C=100.0, random_state=1)\n",
    "lr1.fit(X_train_std, y_train)\n",
    "lr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.20.0'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn; sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> due to above warnings defined a new model <br>\n",
    "solver : str, {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'}, default: 'liblinear'. -----> lbfgs <br>\n",
    "multi_class : str, {'ovr', 'multinomial', 'auto'}, default: 'ovr' -----> auto\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='auto',\n",
       "          n_jobs=None, penalty='l2', random_state=1, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(C=100.0, random_state=1, solver=\"lbfgs\", multi_class=\"auto\")\n",
    "lr.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> This plot is different from book, because different solver and multi_class </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRBJJCUpERBJJCUpERBLp/wMdprp1NwQGQwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#utility.plot_decision_regions_with_test(X_combined_std, y_combined, classifier=lr, test_idx=range(105, 150))\n",
    "\n",
    "utility.plot_decision_regions(X_combined_std, y_combined, classifier=lr)\n",
    "\n",
    "plt.xlabel('petal length [standardized]')\n",
    "plt.ylabel('petal width [standardized]')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('images/03_06.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRBJJCUpERBJJCUpERBLp/wMdprp1NwQGQwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#utility.plot_decision_regions_with_test(X_combined_std, y_combined, classifier=lr1, test_idx=range(105, 150))\n",
    "\n",
    "utility.plot_decision_regions(X_combined_std, y_combined, classifier=lr)\n",
    "\n",
    "plt.xlabel('petal length [standardized]')\n",
    "plt.ylabel('petal width [standardized]')\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()\n",
    "#plt.savefig('images/03_06.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.65010814e-04, 9.99534989e-01],\n",
       "       [4.65010814e-04, 9.99534989e-01],\n",
       "       [3.36666246e-04, 9.99663334e-01]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.predict_proba(X_test_std[:3, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.predict_proba(X_test_std[:3, :]).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.predict_proba(X_test_std[:3, :]).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.predict(X_test_std[:3, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.predict(X_test_std[0, :].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.3412724  -1.31297673] (2,)\n",
      "[[-1.3412724  -1.31297673]] (1, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_std[0, :], X_test_std[0, :].shape) # this is single sample, shape should be (1,2)\n",
    "print(X_test_std[0, :].reshape(1, -1), X_test_std[0, :].reshape(1,-1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Reshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on LogisticRegression in module sklearn.linear_model.logistic object:\n",
      "\n",
      "class LogisticRegression(sklearn.base.BaseEstimator, sklearn.linear_model.base.LinearClassifierMixin, sklearn.linear_model.base.SparseCoefMixin)\n",
      " |  Logistic Regression (aka logit, MaxEnt) classifier.\n",
      " |  \n",
      " |  In the multiclass case, the training algorithm uses the one-vs-rest (OvR)\n",
      " |  scheme if the 'multi_class' option is set to 'ovr', and uses the cross-\n",
      " |  entropy loss if the 'multi_class' option is set to 'multinomial'.\n",
      " |  (Currently the 'multinomial' option is supported only by the 'lbfgs',\n",
      " |  'sag' and 'newton-cg' solvers.)\n",
      " |  \n",
      " |  This class implements regularized logistic regression using the\n",
      " |  'liblinear' library, 'newton-cg', 'sag' and 'lbfgs' solvers. It can handle\n",
      " |  both dense and sparse input. Use C-ordered arrays or CSR matrices\n",
      " |  containing 64-bit floats for optimal performance; any other input format\n",
      " |  will be converted (and copied).\n",
      " |  \n",
      " |  The 'newton-cg', 'sag', and 'lbfgs' solvers support only L2 regularization\n",
      " |  with primal formulation. The 'liblinear' solver supports both L1 and L2\n",
      " |  regularization, with a dual formulation only for the L2 penalty.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <logistic_regression>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  penalty : str, 'l1' or 'l2', default: 'l2'\n",
      " |      Used to specify the norm used in the penalization. The 'newton-cg',\n",
      " |      'sag' and 'lbfgs' solvers support only l2 penalties.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |         l1 penalty with SAGA solver (allowing 'multinomial' + L1)\n",
      " |  \n",
      " |  dual : bool, default: False\n",
      " |      Dual or primal formulation. Dual formulation is only implemented for\n",
      " |      l2 penalty with liblinear solver. Prefer dual=False when\n",
      " |      n_samples > n_features.\n",
      " |  \n",
      " |  tol : float, default: 1e-4\n",
      " |      Tolerance for stopping criteria.\n",
      " |  \n",
      " |  C : float, default: 1.0\n",
      " |      Inverse of regularization strength; must be a positive float.\n",
      " |      Like in support vector machines, smaller values specify stronger\n",
      " |      regularization.\n",
      " |  \n",
      " |  fit_intercept : bool, default: True\n",
      " |      Specifies if a constant (a.k.a. bias or intercept) should be\n",
      " |      added to the decision function.\n",
      " |  \n",
      " |  intercept_scaling : float, default 1.\n",
      " |      Useful only when the solver 'liblinear' is used\n",
      " |      and self.fit_intercept is set to True. In this case, x becomes\n",
      " |      [x, self.intercept_scaling],\n",
      " |      i.e. a \"synthetic\" feature with constant value equal to\n",
      " |      intercept_scaling is appended to the instance vector.\n",
      " |      The intercept becomes ``intercept_scaling * synthetic_feature_weight``.\n",
      " |  \n",
      " |      Note! the synthetic feature weight is subject to l1/l2 regularization\n",
      " |      as all other features.\n",
      " |      To lessen the effect of regularization on synthetic feature weight\n",
      " |      (and therefore on the intercept) intercept_scaling has to be increased.\n",
      " |  \n",
      " |  class_weight : dict or 'balanced', default: None\n",
      " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
      " |      If not given, all classes are supposed to have weight one.\n",
      " |  \n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``.\n",
      " |  \n",
      " |      Note that these weights will be multiplied with sample_weight (passed\n",
      " |      through the fit method) if sample_weight is specified.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *class_weight='balanced'*\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional, default: None\n",
      " |      The seed of the pseudo random number generator to use when shuffling\n",
      " |      the data.  If int, random_state is the seed used by the random number\n",
      " |      generator; If RandomState instance, random_state is the random number\n",
      " |      generator; If None, the random number generator is the RandomState\n",
      " |      instance used by `np.random`. Used when ``solver`` == 'sag' or\n",
      " |      'liblinear'.\n",
      " |  \n",
      " |  solver : str, {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'},              default: 'liblinear'.\n",
      " |  \n",
      " |      Algorithm to use in the optimization problem.\n",
      " |  \n",
      " |      - For small datasets, 'liblinear' is a good choice, whereas 'sag' and\n",
      " |        'saga' are faster for large ones.\n",
      " |      - For multiclass problems, only 'newton-cg', 'sag', 'saga' and 'lbfgs'\n",
      " |        handle multinomial loss; 'liblinear' is limited to one-versus-rest\n",
      " |        schemes.\n",
      " |      - 'newton-cg', 'lbfgs' and 'sag' only handle L2 penalty, whereas\n",
      " |        'liblinear' and 'saga' handle L1 penalty.\n",
      " |  \n",
      " |      Note that 'sag' and 'saga' fast convergence is only guaranteed on\n",
      " |      features with approximately the same scale. You can\n",
      " |      preprocess the data with a scaler from sklearn.preprocessing.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         Stochastic Average Gradient descent solver.\n",
      " |      .. versionadded:: 0.19\n",
      " |         SAGA solver.\n",
      " |      .. versionchanged:: 0.20\n",
      " |          Default will change from 'liblinear' to 'lbfgs' in 0.22.\n",
      " |  \n",
      " |  max_iter : int, default: 100\n",
      " |      Useful only for the newton-cg, sag and lbfgs solvers.\n",
      " |      Maximum number of iterations taken for the solvers to converge.\n",
      " |  \n",
      " |  multi_class : str, {'ovr', 'multinomial', 'auto'}, default: 'ovr'\n",
      " |      If the option chosen is 'ovr', then a binary problem is fit for each\n",
      " |      label. For 'multinomial' the loss minimised is the multinomial loss fit\n",
      " |      across the entire probability distribution, *even when the data is\n",
      " |      binary*. 'multinomial' is unavailable when solver='liblinear'.\n",
      " |      'auto' selects 'ovr' if the data is binary, or if solver='liblinear',\n",
      " |      and otherwise selects 'multinomial'.\n",
      " |  \n",
      " |      .. versionadded:: 0.18\n",
      " |         Stochastic Average Gradient descent solver for 'multinomial' case.\n",
      " |      .. versionchanged:: 0.20\n",
      " |          Default will change from 'ovr' to 'auto' in 0.22.\n",
      " |  \n",
      " |  verbose : int, default: 0\n",
      " |      For the liblinear and lbfgs solvers set verbose to any positive\n",
      " |      number for verbosity.\n",
      " |  \n",
      " |  warm_start : bool, default: False\n",
      " |      When set to True, reuse the solution of the previous call to fit as\n",
      " |      initialization, otherwise, just erase the previous solution.\n",
      " |      Useless for liblinear solver. See :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers.\n",
      " |  \n",
      " |  n_jobs : int or None, optional (default=None)\n",
      " |      Number of CPU cores used when parallelizing over classes if\n",
      " |      multi_class='ovr'\". This parameter is ignored when the ``solver`` is\n",
      " |      set to 'liblinear' regardless of whether 'multi_class' is specified or\n",
      " |      not. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
      " |      context. ``-1`` means using all processors.\n",
      " |      See :term:`Glossary <n_jobs>` for more details.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  \n",
      " |  coef_ : array, shape (1, n_features) or (n_classes, n_features)\n",
      " |      Coefficient of the features in the decision function.\n",
      " |  \n",
      " |      `coef_` is of shape (1, n_features) when the given problem is binary.\n",
      " |      In particular, when `multi_class='multinomial'`, `coef_` corresponds\n",
      " |      to outcome 1 (True) and `-coef_` corresponds to outcome 0 (False).\n",
      " |  \n",
      " |  intercept_ : array, shape (1,) or (n_classes,)\n",
      " |      Intercept (a.k.a. bias) added to the decision function.\n",
      " |  \n",
      " |      If `fit_intercept` is set to False, the intercept is set to zero.\n",
      " |      `intercept_` is of shape (1,) when the given problem is binary.\n",
      " |      In particular, when `multi_class='multinomial'`, `intercept_`\n",
      " |      corresponds to outcome 1 (True) and `-intercept_` corresponds to\n",
      " |      outcome 0 (False).\n",
      " |  \n",
      " |  n_iter_ : array, shape (n_classes,) or (1, )\n",
      " |      Actual number of iterations for all classes. If binary or multinomial,\n",
      " |      it returns only 1 element. For liblinear solver, only the maximum\n",
      " |      number of iteration across all classes is given.\n",
      " |  \n",
      " |      .. versionchanged:: 0.20\n",
      " |  \n",
      " |          In SciPy <= 1.0.0 the number of lbfgs iterations may exceed\n",
      " |          ``max_iter``. ``n_iter_`` will now report at most ``max_iter``.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.datasets import load_iris\n",
      " |  >>> from sklearn.linear_model import LogisticRegression\n",
      " |  >>> X, y = load_iris(return_X_y=True)\n",
      " |  >>> clf = LogisticRegression(random_state=0, solver='lbfgs',\n",
      " |  ...                          multi_class='multinomial').fit(X, y)\n",
      " |  >>> clf.predict(X[:2, :])\n",
      " |  array([0, 0])\n",
      " |  >>> clf.predict_proba(X[:2, :]) # doctest: +ELLIPSIS\n",
      " |  array([[9.8...e-01, 1.8...e-02, 1.4...e-08],\n",
      " |         [9.7...e-01, 2.8...e-02, ...e-08]])\n",
      " |  >>> clf.score(X, y)\n",
      " |  0.97...\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  SGDClassifier : incrementally trained logistic regression (when given\n",
      " |      the parameter ``loss=\"log\"``).\n",
      " |  LogisticRegressionCV : Logistic regression with built-in cross validation\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The underlying C implementation uses a random number generator to\n",
      " |  select features when fitting the model. It is thus not uncommon,\n",
      " |  to have slightly different results for the same input data. If\n",
      " |  that happens, try with a smaller tol parameter.\n",
      " |  \n",
      " |  Predict output may not match that of standalone liblinear in certain\n",
      " |  cases. See :ref:`differences from liblinear <liblinear_differences>`\n",
      " |  in the narrative documentation.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  LIBLINEAR -- A Library for Large Linear Classification\n",
      " |      http://www.csie.ntu.edu.tw/~cjlin/liblinear/\n",
      " |  \n",
      " |  SAG -- Mark Schmidt, Nicolas Le Roux, and Francis Bach\n",
      " |      Minimizing Finite Sums with the Stochastic Average Gradient\n",
      " |      https://hal.inria.fr/hal-00860051/document\n",
      " |  \n",
      " |  SAGA -- Defazio, A., Bach F. & Lacoste-Julien S. (2014).\n",
      " |      SAGA: A Fast Incremental Gradient Method With Support\n",
      " |      for Non-Strongly Convex Composite Objectives\n",
      " |      https://arxiv.org/abs/1407.0202\n",
      " |  \n",
      " |  Hsiang-Fu Yu, Fang-Lan Huang, Chih-Jen Lin (2011). Dual coordinate descent\n",
      " |      methods for logistic regression and maximum entropy models.\n",
      " |      Machine Learning 85(1-2):41-75.\n",
      " |      http://www.csie.ntu.edu.tw/~cjlin/papers/maxent_dual.pdf\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LogisticRegression\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.linear_model.base.LinearClassifierMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.linear_model.base.SparseCoefMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='warn', max_iter=100, multi_class='warn', verbose=0, warm_start=False, n_jobs=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit the model according to the given training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          Training vector, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,) or (n_samples, n_targets)\n",
      " |          Target vector relative to X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,) optional\n",
      " |          Array of weights that are assigned to individual samples.\n",
      " |          If not provided, then each sample is given unit weight.\n",
      " |      \n",
      " |          .. versionadded:: 0.17\n",
      " |             *sample_weight* support to LogisticRegression.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Log of probability estimates.\n",
      " |      \n",
      " |      The returned estimates for all classes are ordered by the\n",
      " |      label of classes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like, shape = [n_samples, n_classes]\n",
      " |          Returns the log-probability of the sample for each class in the\n",
      " |          model, where classes are ordered as they are in ``self.classes_``.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Probability estimates.\n",
      " |      \n",
      " |      The returned estimates for all classes are ordered by the\n",
      " |      label of classes.\n",
      " |      \n",
      " |      For a multi_class problem, if multi_class is set to be \"multinomial\"\n",
      " |      the softmax function is used to find the predicted probability of\n",
      " |      each class.\n",
      " |      Else use a one-vs-rest approach, i.e calculate the probability\n",
      " |      of each class assuming it to be positive using the logistic function.\n",
      " |      and normalize these values across all the classes.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      T : array-like, shape = [n_samples, n_classes]\n",
      " |          Returns the probability of the sample for each class in the model,\n",
      " |          where classes are ordered as they are in ``self.classes_``.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model.base.LinearClassifierMixin:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Predict confidence scores for samples.\n",
      " |      \n",
      " |      The confidence score for a sample is the signed distance of that\n",
      " |      sample to the hyperplane.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)\n",
      " |          Confidence scores per (sample, class) combination. In the binary\n",
      " |          case, confidence score for self.classes_[1] where >0 means this\n",
      " |          class would be predicted.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class labels for samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape [n_samples]\n",
      " |          Predicted class label per sample.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model.base.SparseCoefMixin:\n",
      " |  \n",
      " |  densify(self)\n",
      " |      Convert coefficient matrix to dense array format.\n",
      " |      \n",
      " |      Converts the ``coef_`` member (back) to a numpy.ndarray. This is the\n",
      " |      default format of ``coef_`` and is required for fitting, so calling\n",
      " |      this method is only required on models that have previously been\n",
      " |      sparsified; otherwise, it is a no-op.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator\n",
      " |  \n",
      " |  sparsify(self)\n",
      " |      Convert coefficient matrix to sparse format.\n",
      " |      \n",
      " |      Converts the ``coef_`` member to a scipy.sparse matrix, which for\n",
      " |      L1-regularized models can be much more memory- and storage-efficient\n",
      " |      than the usual numpy.ndarray representation.\n",
      " |      \n",
      " |      The ``intercept_`` member is not converted.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For non-sparse models, i.e. when there are not many zeros in ``coef_``,\n",
      " |      this may actually *increase* memory usage, so use this method with\n",
      " |      care. A rule of thumb is that the number of zero elements, which can\n",
      " |      be computed with ``(coef_ == 0).sum()``, must be more than 50% for this\n",
      " |      to provide significant benefits.\n",
      " |      \n",
      " |      After calling this method, further fitting with the partial_fit\n",
      " |      method (if any) will not work until you call densify.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(lr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_estimator_type', '_get_param_names', '_predict_proba_lr', 'class_weight', 'classes_', 'coef_', 'decision_function', 'densify', 'dual', 'fit', 'fit_intercept', 'get_params', 'intercept_', 'intercept_scaling', 'max_iter', 'multi_class', 'n_iter_', 'n_jobs', 'penalty', 'predict', 'predict_log_proba', 'predict_proba', 'random_state', 'score', 'set_params', 'solver', 'sparsify', 'tol', 'verbose', 'warm_start']\n"
     ]
    }
   ],
   "source": [
    "print(dir(lr1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9], dtype=int32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.68175478, -4.93017223]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-6.42099752])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.3412724 , -1.31297673],\n",
       "       [-1.3412724 , -1.31297673],\n",
       "       [-1.39813811, -1.31297673]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_std[:3, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.65010814e-04, 9.99534989e-01],\n",
       "       [4.65010814e-04, 9.99534989e-01],\n",
       "       [3.36666246e-04, 9.99663334e-01]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.predict_proba(X_test_std[:3, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.predict(X_test_std[:3, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_std[1, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr1.coef_.shape # 1 models, 2 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = np.dot(lr1.coef_, X_test_std[2, :]) + lr1.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.99608176])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99966333])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prob(x, w, bias):\n",
    "    probs = np.array([])\n",
    "    for i in range(len(w)):\n",
    "        z = np.dot(x, w[i]) + bias[i]\n",
    "        prob = sigmoid(z)\n",
    "        probs = np.append(probs, prob)\n",
    "        #probs = np.append(probs, z)\n",
    "        \n",
    "    print(probs)\n",
    "    probs_new = np.array([])\n",
    "    for i in probs:\n",
    "        i = np.exp(i)/np.sum(np.exp(probs))\n",
    "        probs_new = np.append(probs_new, i)\n",
    "        \n",
    "    return probs_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99966333]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prob(X_test_std[2, :], lr1.coef_, lr1.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.98720613207489"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.array([2])\n",
    "x=np.append(x, [4])\n",
    "sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-0614bb589e53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_prob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_std\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-69-0dc5b216f3d4>\u001b[0m in \u001b[0;36mget_prob\u001b[1;34m(x, w, bias)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "get_prob(X_test_std[0, :], lr1.coef_[0], lr1.intercept_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prob(X_test_std[0, :], lr1.coef_[1], lr1.intercept_[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prob(X_test_std[0, :], lr1.coef_[2], lr1.intercept_[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
